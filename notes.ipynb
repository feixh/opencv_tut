{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV I/O functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above piece of code imported all the packages we need through this tutorial.\n",
    "\n",
    "Now, let's load an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load, display and save images\n",
    "Use the function [`cv2.imread()`](http://docs.opencv.org/3.0-beta/modules/imgcodecs/doc/reading_and_writing_images.html?highlight=imread#cv2.imread) to read an image. The function accepts two arguments, the first argument is the path of the image and the second argument is a flag indicating how to decode the image, there are three options:\n",
    "- `cv2.IMREAD_COLOR`: load the image in color mode\n",
    "- `cv2.IMREAD_GRAYSCALE`: load the image in grayscale mode\n",
    "- `cv2.IMREAD_UNCHANGED`: load the image in color+alpha mode if the image has an alpha (controls transparency) channel, otherwise in color mode\n",
    "\n",
    "Use the function [`cv2.imshow()`](http://docs.opencv.org/3.0-beta/modules/highgui/doc/user_interface.html?highlight=imshow#cv2.imshow) to display an image. This function accepts two arguments, the first argument is the window name and the second one is the image, which is an numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the image\n",
    "image = cv2.imread('dog.png', cv2.IMREAD_COLOR)\n",
    "# TODO: check size of images loaded with different options\n",
    "print image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display the image\n",
    "cv2.imshow('display', image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code above doesn't show us the image, we need to run the \"event loop\" and go into the display thread by calling [`cv2.waitKey()`](http://docs.opencv.org/3.0-beta/modules/highgui/doc/user_interface.html?highlight=waitkey#waitkey). You can either give this function an integer argument, which is the amount of time to wait (in milliseconds) or leave out the argument, which means the display thread will wait forever until you press a key. The value returned is the ASCII code of the key you pressed. We can use this to wait for a specific key stroke and manipulate the image in different ways according to the key pressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# press any key to close the window\n",
    "cv2.waitKey()\n",
    "# close the window\n",
    "cv2.destroyWindow('display')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "Wait for a specific key, say 'x'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('dog.png', cv2.IMREAD_UNCHANGED)\n",
    "key = None\n",
    "while key != ord('x'):\n",
    "    cv2.imshow('display', image)\n",
    "    # wait for 30 ms\n",
    "    key = cv2.waitKey(30)\n",
    "# close the window\n",
    "cv2.destroyWindow('display')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example** \n",
    "\n",
    "Do different things to the image according to the key pressed.\n",
    "- 'v': flip the image vertically\n",
    "- 'h': flip the image horizontally\n",
    "- 'u': upsample the image by a factor of 2\n",
    "- 'd': downsample the image by a factor of 2\n",
    "- 'r': show the red channel of the image\n",
    "- 'g': show the green channel of the image\n",
    "- 'b': show the blue channel of the image\n",
    "- 's': save the modified image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('dog.png', cv2.IMREAD_UNCHANGED)\n",
    "key = None\n",
    "while key != ord('x'):\n",
    "    cv2.imshow('original', image)\n",
    "    if key == ord('v'):\n",
    "        image_new = np.flipud(image)\n",
    "        cv2.imshow('modified', image_new)\n",
    "    elif key == ord('h'):\n",
    "        image_new = np.fliplr(image)\n",
    "        cv2.imshow('modified', image_new)\n",
    "    elif key == ord('u'):\n",
    "        # resize the input image to desired size\n",
    "        # 1st arg: image\n",
    "        # 2nd arg: desired size\n",
    "        # 3rd arg: interpolation method, default is bilinear\n",
    "        image_new = cv2.resize(image, \n",
    "                           dsize=(1024, 1024), \n",
    "                           interpolation=cv2.INTER_LINEAR)\n",
    "        cv2.imshow('modified', image_new)\n",
    "    elif key == ord('d'):\n",
    "        image_new = cv2.resize(image, \n",
    "                           (256, 256),\n",
    "                          interpolation=cv2.INTER_LINEAR)\n",
    "        cv2.imshow('modified', image_new)   \n",
    "    elif key == ord('r'):\n",
    "        image_new = image.copy()\n",
    "        image_new[..., [0,1]] = 0\n",
    "        cv2.imshow('modified', image_new)\n",
    "    elif key == ord('g'):\n",
    "        image_new = image.copy()\n",
    "        image_new[..., [0,2]] = 0\n",
    "        cv2.imshow('modified', image_new)\n",
    "    elif key == ord('b'):\n",
    "        image_new = image.copy()\n",
    "        image_new[..., [1,2]] = 0\n",
    "        cv2.imshow('modified', image_new)\n",
    "    elif key == ord('s'):\n",
    "        # save the image to a given path\n",
    "        # 1st arg: desired image path\n",
    "        # 2nd arg: image data\n",
    "        cv2.imwrite('dog_new.png', image_new)                \n",
    "    # wait for 30 ms\n",
    "    key = cv2.waitKey(30)\n",
    "# close all window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**useful functions**\n",
    "- [`cv2.imread()`](http://docs.opencv.org/3.0-beta/modules/imgcodecs/doc/reading_and_writing_images.html?highlight=imread#cv2.imread)\n",
    "- [`cv2.imshow()`](http://docs.opencv.org/3.0-beta/modules/highgui/doc/user_interface.html?highlight=imshow#cv2.imshow)\n",
    "- [`cv2.imwrite()`](http://docs.opencv.org/3.0-beta/modules/imgcodecs/doc/reading_and_writing_images.html?highlight=imwrite#cv2.imwrite)\n",
    "- [`cv2.waitKey()`](http://docs.opencv.org/3.0-beta/modules/highgui/doc/user_interface.html?highlight=waitkey#waitkey)\n",
    "- [`cv2.resize()`](http://docs.opencv.org/3.0-beta/modules/imgproc/doc/geometric_transformations.html?highlight=resize#cv2.resize)\n",
    "- More on [reading & writing images](http://docs.opencv.org/3.0-beta/modules/imgcodecs/doc/imgcodecs.html)\n",
    "- More on [geometric image transformations]( http://docs.opencv.org/3.0-beta/modules/imgproc/doc/geometric_transformations.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use webcam to capture a video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### launch the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an object which can capture images.\n",
    "cap = cv2.VideoCapture()\n",
    "# Camera devices are indexed by integers, \n",
    "# typically your laptop webcam has device number 0.\n",
    "# Do a small loop to find the proper camera and open it.\n",
    "for i in range(10):\n",
    "    if cap.open(i):\n",
    "        print 'camera {} launched'.format(i)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grab images from the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = None\n",
    "while key != ord('x'):\n",
    "    status, image = cap.read()\n",
    "    assert status, 'failed to grab image from camera'\n",
    "    cv2.imshow('display', image)\n",
    "    key = cv2.waitKey(30)\n",
    "cv2.destroyWindow('display')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### release the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# release the camera\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application: Face detection in a video\n",
    "\n",
    "TODO: theory behind face detection ... and then the related functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a cascade face detector.\n",
    "configure_file = 'haarcascade_frontalface_default.xml'\n",
    "face_detector = cv2.CascadeClassifier(configure_file)\n",
    "# let's load the lena image\n",
    "image = cv2.imread('lena.jpg')\n",
    "# The face detector takes a gray scale image as input,\n",
    "# so we need to convert the color image to grayscale image first.\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# Detect faces in multi-scale.\n",
    "# TODO: arguments explained ...\n",
    "faces = face_detector.detectMultiScale(gray, 1.1, 2)\n",
    "for (x, y, w, h) in faces:\n",
    "    image = cv2.rectangle(image, (x,y), (x+w, y+h), (255, 0, 0), 2)\n",
    "cv2.imshow('display', image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyWindow('display')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions explained**\n",
    "\n",
    "- [`cv2.rectangle()`](http://docs.opencv.org/3.0-beta/modules/imgproc/doc/drawing_functions.html#rectangle): draw a rectangle on the given image (1st argument). Need to specify the top-left & bottom-right corners of the rectangle (2nd & 3rd argument, a tuple), RGB color of the rectangle border (4th argument) and width of border (5th argument).\n",
    "- Other useful drawing functions include\n",
    "[`cv2.circle()`](http://docs.opencv.org/3.0-beta/modules/imgproc/doc/drawing_functions.html#circle)(draw circles), \n",
    "[`cv2.line()`](http://docs.opencv.org/3.0-beta/modules/imgproc/doc/drawing_functions.html#line)(draw straight lines)\n",
    "and [`cv2.putText()`](http://docs.opencv.org/3.0-beta/modules/imgproc/doc/drawing_functions.html#puttext)(overlay texts on image).\n",
    "- More on [drawing functions](http://docs.opencv.org/3.0-beta/modules/imgproc/doc/drawing_functions.html#)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### put everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera 0 launched\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/tmp/binarydeb/ros-kinetic-opencv3-3.2.0/modules/imgproc/src/imgwarp.cpp:3493: error: (-215) dsize.area() > 0 || (inv_scale_x > 0 && inv_scale_y > 0) in function resize\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fa02d75e91ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m#         image = cv2.rectangle(image, (x,y), (x+w,y+h), (255,0,0), 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverlay_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-fa02d75e91ec>\u001b[0m in \u001b[0;36moverlay_image\u001b[0;34m(foreground, background, rect)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mresized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforeground\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackground\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /tmp/binarydeb/ros-kinetic-opencv3-3.2.0/modules/imgproc/src/imgwarp.cpp:3493: error: (-215) dsize.area() > 0 || (inv_scale_x > 0 && inv_scale_y > 0) in function resize\n"
     ]
    }
   ],
   "source": [
    "def overlay_image(foreground, background, rect):\n",
    "    \"\"\"\n",
    "    overlay the foreground image on the background image \n",
    "    at the specified location\n",
    "    :param foreground: the foreground image, numpy array\n",
    "    :param background: the background image, numpy array\n",
    "    :param rect: a rectangle indicating where to overlay\n",
    "    :return: overlaid image\n",
    "    \"\"\"\n",
    "    row, col = foreground.shape[0:2]\n",
    "    x, y, w, h = rect\n",
    "    center = x + w/2, y + h/2\n",
    "    ratio_x, ratio_y = w/row, h/row\n",
    "    ratio = max(ratio_x, ratio_y)\n",
    "    row, col = int(ratio*row), int(ratio*col)\n",
    "    resized = cv2.resize(foreground, dsize=(row, col))\n",
    "    ret = background.copy()\n",
    "    ret[x-row/2:x+row/2, y-col/2:y+col/2] = resized.copy()\n",
    "    return ret\n",
    "                         \n",
    "\n",
    "    \n",
    "face = cv2.imread('smiling_face.jpg')\n",
    "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture()\n",
    "for i in range(10):\n",
    "    if cap.open(i):\n",
    "        print 'camera {} launched'.format(i)\n",
    "        break\n",
    "key = None\n",
    "face_location = None\n",
    "while key != ord('x'):\n",
    "    status, image = cap.read()\n",
    "    assert status, 'failed to grab image from camera'\n",
    "    # convert color image to grayscale image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_detector.detectMultiScale(gray, 1.1, 10)\n",
    "    if len(faces) != 1:\n",
    "        # use the previous detection result\n",
    "        pass\n",
    "    else:\n",
    "        face_location = faces[0]\n",
    "    if face_location is not None:\n",
    "        x, y, w, h = face_location\n",
    "#         image = cv2.rectangle(image, (x,y), (x+w,y+h), (255,0,0), 2)               \n",
    "        image = overlay_image(image, face, face_location)\n",
    "    cv2.imshow('display', image)\n",
    "    key = cv2.waitKey(30)\n",
    "cv2.destroyWindow('display')\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature detection & matching/tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful resources\n",
    "- [OpenCV API reference](http://docs.opencv.org/2.4/modules/refman.html)\n",
    "- [OpenCV official repository](https://github.com/opencv/opencv)\n",
    "- [OpenCV code samples in Python](https://github.com/opencv/opencv/tree/master/samples/python)\n",
    "- [vlfeat tutorials](http://www.vlfeat.org/overview/tut.html)\n",
    "- [numpy tutorial](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html)\n",
    "- [Jupyter notebook](https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
