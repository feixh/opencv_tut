{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV I/O functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above piece of code imported all the packages we need through this tutorial.\n",
    "\n",
    "Now, let's load an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load, display and save images\n",
    "Use the function [`cv2.imread()`](http://docs.opencv.org/3.0-beta/modules/imgcodecs/doc/reading_and_writing_images.html?highlight=imread#cv2.imread) to read an image. The function accepts two arguments, the first argument is the path of the image and the second argument is a flag indicating how to decode the image, there are three options:\n",
    "- `cv2.IMREAD_COLOR`: load the image in color mode\n",
    "- `cv2.IMREAD_GRAYSCALE`: load the image in grayscale mode\n",
    "- `cv2.IMREAD_UNCHANGED`: load the image in color+alpha mode if the image has an alpha (controls transparency) channel, otherwise in color mode\n",
    "\n",
    "Use the function [`cv2.imshow()`](http://docs.opencv.org/3.0-beta/modules/highgui/doc/user_interface.html?highlight=imshow#cv2.imshow) to display an image. This function accepts two arguments, the first argument is the window name and the second one is the image, which is an numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the image\n",
    "image = cv2.imread('dog.png', cv2.IMREAD_COLOR)\n",
    "# TODO: check size of images loaded with different options\n",
    "print image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display the image\n",
    "cv2.imshow('display', image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code above doesn't show us the image, we need to run the \"event loop\" and go into the display thread by calling [`cv2.waitKey()`](http://docs.opencv.org/3.0-beta/modules/highgui/doc/user_interface.html?highlight=waitkey#waitkey). You can either give this function an integer argument, which is the amount of time to wait (in milliseconds) or leave out the argument, which means the display thread will wait forever until you press a key. The value returned is the ASCII code of the key you pressed. We can use this to wait for a specific key stroke and manipulate the image in different ways according to the key pressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# press any key to close the window\n",
    "cv2.waitKey()\n",
    "# close the window\n",
    "cv2.destroyWindow('display')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "Wait for a specific key, say 'x'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('dog.png', cv2.IMREAD_UNCHANGED)\n",
    "key = None\n",
    "while key != ord('x'):\n",
    "    cv2.imshow('display', image)\n",
    "    # wait for 30 ms\n",
    "    key = cv2.waitKey(30)\n",
    "# close the window\n",
    "cv2.destroyWindow('display')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example** \n",
    "\n",
    "Do different things to the image according to the key pressed.\n",
    "- 'v': flip the image vertically\n",
    "- 'h': flip the image horizontally\n",
    "- 'u': upsample the image by a factor of 2\n",
    "- 'd': downsample the image by a factor of 2\n",
    "- 'r': show the red channel of the image\n",
    "- 'g': show the green channel of the image\n",
    "- 'b': show the blue channel of the image\n",
    "- 's': save the modified image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('dog.png', cv2.IMREAD_UNCHANGED)\n",
    "key = None\n",
    "while key != ord('x'):\n",
    "    cv2.imshow('original', image)\n",
    "    if key == ord('v'):\n",
    "        image_new = np.flipud(image)\n",
    "        cv2.imshow('modified', image_new)\n",
    "    elif key == ord('h'):\n",
    "        image_new = np.fliplr(image)\n",
    "        cv2.imshow('modified', image_new)\n",
    "    elif key == ord('u'):\n",
    "        # resize the input image to desired size\n",
    "        # 1st arg: image\n",
    "        # 2nd arg: desired size\n",
    "        # 3rd arg: interpolation method, default is bilinear\n",
    "        image_new = cv2.resize(image, \n",
    "                           dsize=(1024, 1024), \n",
    "                           interpolation=cv2.INTER_LINEAR)\n",
    "        cv2.imshow('modified', image_new)\n",
    "    elif key == ord('d'):\n",
    "        image_new = cv2.resize(image, \n",
    "                           (256, 256),\n",
    "                          interpolation=cv2.INTER_LINEAR)\n",
    "        cv2.imshow('modified', image_new)   \n",
    "    elif key == ord('r'):\n",
    "        image_new = image.copy()\n",
    "        image_new[..., [0,1]] = 0\n",
    "        cv2.imshow('modified', image_new)\n",
    "    elif key == ord('g'):\n",
    "        image_new = image.copy()\n",
    "        image_new[..., [0,2]] = 0\n",
    "        cv2.imshow('modified', image_new)\n",
    "    elif key == ord('b'):\n",
    "        image_new = image.copy()\n",
    "        image_new[..., [1,2]] = 0\n",
    "        cv2.imshow('modified', image_new)\n",
    "    elif key == ord('s'):\n",
    "        # save the image to a given path\n",
    "        # 1st arg: desired image path\n",
    "        # 2nd arg: image data\n",
    "        cv2.imwrite('dog_new.png', image_new)                \n",
    "    # wait for 30 ms\n",
    "    key = cv2.waitKey(30)\n",
    "# close all window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**useful functions**\n",
    "- [`cv2.imread()`](http://docs.opencv.org/3.0-beta/modules/imgcodecs/doc/reading_and_writing_images.html?highlight=imread#cv2.imread)\n",
    "- [`cv2.imshow()`](http://docs.opencv.org/3.0-beta/modules/highgui/doc/user_interface.html?highlight=imshow#cv2.imshow)\n",
    "- [`cv2.imwrite()`](http://docs.opencv.org/3.0-beta/modules/imgcodecs/doc/reading_and_writing_images.html?highlight=imwrite#cv2.imwrite)\n",
    "- [`cv2.waitKey()`](http://docs.opencv.org/3.0-beta/modules/highgui/doc/user_interface.html?highlight=waitkey#waitkey)\n",
    "- [`cv2.resize()`](http://docs.opencv.org/3.0-beta/modules/imgproc/doc/geometric_transformations.html?highlight=resize#cv2.resize)\n",
    "- More on [reading & writing images](http://docs.opencv.org/3.0-beta/modules/imgcodecs/doc/imgcodecs.html)\n",
    "- More on [geometric image transformations]( http://docs.opencv.org/3.0-beta/modules/imgproc/doc/geometric_transformations.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use webcam to capture a video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### launch the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an object which can capture images.\n",
    "cap = cv2.VideoCapture()\n",
    "# Camera devices are indexed by integers, \n",
    "# typically your laptop webcam has device number 0.\n",
    "# Do a small loop to find the proper camera and open it.\n",
    "for i in range(10):\n",
    "    if cap.open(i):\n",
    "        print 'camera {} launched'.format(i)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grab images from the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = None\n",
    "while key != ord('x'):\n",
    "    status, image = cap.read()\n",
    "    assert status, 'failed to grab image from camera'\n",
    "    cv2.imshow('display', image)\n",
    "    key = cv2.waitKey(30)\n",
    "cv2.destroyWindow('display')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### release the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# release the camera\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application: face detection in a video\n",
    "\n",
    "TODO: theory behind face detection ... and then the related functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cascade face detector.\n",
    "configure_file = 'haarcascade_frontalface_default.xml'\n",
    "face_detector = cv2.CascadeClassifier(configure_file)\n",
    "# let's load the lena image\n",
    "image = cv2.imread('lena.jpg')\n",
    "# The face detector takes a gray scale image as input,\n",
    "# so we need to convert the color image to grayscale image first.\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_detector.detectMultiScale(gray, 1.1, 2)\n",
    "for (x, y, w, h) in faces:\n",
    "    image = cv2.rectangle(image, (x,y), (x+w, y+h), (255, 0, 0), 2)\n",
    "cv2.imshow('display', image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyWindow('display')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### put everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "# Create an object which can capture images.\n",
    "cap = cv2.VideoCapture()\n",
    "# Camera devices are indexed by integers, \n",
    "# typically your laptop webcam has device number 0.\n",
    "# Do a small loop to find the proper camera and open it.\n",
    "for i in range(10):\n",
    "    if cap.open(i):\n",
    "        print 'camera {} launched'.format(i)\n",
    "        break\n",
    "key = None\n",
    "while key != ord('x'):\n",
    "    status, image = cap.read()\n",
    "    assert status, 'failed to grab image from camera'\n",
    "    # convert color image to grayscale image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)    \n",
    "    faces = face_detector.detectMultiScale(gray, 1.1, 2)\n",
    "    for (x,y,w,h) in faces:\n",
    "        image = cv2.rectangle(image, (x,y), (x+w,y+h), (255,0,0), 2)               \n",
    "    cv2.imshow('display', image)\n",
    "    key = cv2.waitKey(30)\n",
    "cv2.destroyWindow('display')\n",
    "# release the camera\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful resources\n",
    "- [OpenCV API reference](http://docs.opencv.org/2.4/modules/refman.html)\n",
    "- [OpenCV official repository](https://github.com/opencv/opencv)\n",
    "- [OpenCV code samples in Python](https://github.com/opencv/opencv/tree/master/samples/python)\n",
    "- [vlfeat tutorials](http://www.vlfeat.org/overview/tut.html)\n",
    "- [numpy tutorial](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html)\n",
    "- [Jupyter notebook](https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
